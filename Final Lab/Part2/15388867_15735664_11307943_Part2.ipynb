{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <img src=\"https://miro.medium.com/v2/resize:fit:1200/1*lbDXL0IuitCRz4mpZ7MmfQ.png\" width=55% > </center>\n",
    "\n",
    "<br><br>\n",
    "\n",
    "<center> \n",
    "    <font size=\"6\">Final Lab (Part 2): Image Classification using Convolutional Neural Networks </font>\n",
    "</center>\n",
    "<center> \n",
    "    <font size=\"4\">Computer Vision 1 University of Amsterdam</font> \n",
    "</center>\n",
    "<center> \n",
    "    <font size=\"4\">Due 23:59PM, October 18, 2024 (Amsterdam time)</font> \n",
    "</center>\n",
    "<center> \n",
    "    <font size=\"4\"><b>TA's:  Yue, Konrad & Thies</b></font>\n",
    "</center>\n",
    "\n",
    "<br><br>\n",
    "\n",
    "***\n",
    "\n",
    "<br><br>\n",
    "\n",
    "<center>\n",
    "\n",
    "Student1 ID:  15388867\\\n",
    "Student1 Name: Jose Garcia\n",
    "\n",
    "Student2 ID: 15735664\\\n",
    "Student2 Name: Lisanne Wallaard\n",
    "\n",
    "Student3 ID: 11307943\\\n",
    "Student3 Name: Julio Smidi\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Coding Guidelines**\n",
    "\n",
    "Your code must be handed in this Jupyter notebook, renamed to **StudentID1_StudentID2_StudentID3.ipynb** before the deadline by submitting it to the Canvas Final Lab: Image Classification Assignment. Please also fill out your names and IDs above.\n",
    "\n",
    "For full credit, make sure your notebook follows these guidelines:\n",
    "\n",
    "- Please express your thoughts **concisely**. The number of words does not necessarily correlate with how well you understand the concepts.\n",
    "- Understand the problem as much as you can. When answering a question, provide evidence (qualitative and/or quantitative results, references to papers, figures, etc.) to support your arguments. Not everything might be explicitly asked for, so think about what might strengthen your arguments to make the notebook self-contained and complete.\n",
    "- Tables and figures must be accompanied by a **brief** description. Add a number, a title, and, if applicable, the name and unit of variables in a table, and name and unit of axes and legends in a figure.\n",
    "\n",
    "**Late submissions are not allowed.** Assignments submitted after the strict deadline will not be graded. In case of submission conflicts, TAsâ€™ system clock is taken as reference. We strongly recommend submitting well in advance to avoid last-minute system failure issues.\n",
    "\n",
    "**Environment:** Since this is a project-based assignment, you are free to use any feature descriptor and machine learning tools (e.g., K-means, SVM). You should use Python for your implementation. You are free to use any Python library for this assignment, but make sure to provide a conda environment file!\n",
    "\n",
    "**Plagiarism Note:** Keep in mind that plagiarism (submitted materials which are not your work) is a serious offense and any misconduct will be addressed according to university regulations. This includes using generative tools such as ChatGPT.\n",
    "\n",
    "**Ensure that you save all results/answers to the questions (even if you reuse some code).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Report Preparation**\n",
    "\n",
    "Your tasks include the following:\n",
    "\n",
    "1. **Report Preparation:** For both parts of the final project, students are expected to prepare a report. The report should include all details on implementation approaches, analysis of results for different settings, and visualizations illustrating experiments and performance of your implementation. Grading will be based on the report, so it should be as self-contained as possible. If the report contains faulty results or ambiguities, TAs can refer to your code for clarification. \n",
    "\n",
    "2. **Explanation of Results:** Do not just provide numbers without explanation. Discuss different settings to show your understanding of the material and processes involved.\n",
    "\n",
    "3. **Quantitative Evaluation:** For quantitative evaluation, you are expected to provide the results based on performance (accuracy, learning loss and learning curves). \n",
    "\n",
    "4. **Aim:** Understand the basic Image Classification pipeline using Convolutional Neural Nets (CNN's).\n",
    "\n",
    "5. **Working on Assignments:** Students should work in assigned groups for **two** weeks. Any questions can be discussed on ED.\n",
    "\n",
    "    - **Submission:** Submit your source code and report together in a zip file (`ID1_ID2_ID3_part2.zip`). The report should be a maximum of 10 pages (single-column, including tables and figures, excluding references and appendix). Express thoughts concisely. Tables and figures must be accompanied by a description. Number them and, if applicable, name variables in tables, and label axes in figures.\n",
    "\n",
    "6. **Hyperparameter Search:** In your experiments, remember to perform a hyperparameter search to find the optimal settings for your model(s). Clearly document the search process, the parameters you explored, and how they influenced the performance of your model.\n",
    "\n",
    "8. **Format and Testing:** The report should be in **PDF format**, and the code in **.ipynb format**. Test that all functionality works as expected in the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Overview**\n",
    "\n",
    "- [Section 1: Image Classification on CIFAR-100 (0 points)](#section-1)\n",
    "- [Section 2: Visualizing CIFAR-100 Classes and Subclasses (3 points)](#section-2)\n",
    "- [Section 3: TwoLayerNet Architecture (2 points)](#section-3)\n",
    "- [Section 4: ConvNet Architecture (2 points)](#section-4)\n",
    "- [Section 5: Preparation of Training (7 points)](#section-5)\n",
    "- [Section 6: Training the Networks (5 points)](#section-6)\n",
    "- [Section 7: Setting Up the Hyperparameters (14 points)](#section-7)\n",
    "- [Section 8: Visualizing the STL-10 Dataset and Preparing the Data Loader (3 points)](#section-8)\n",
    "- [Section 9: Fine-tuning ConvNet on STL-10 (14 points)](#section-9)\n",
    "- [Section 10: Bonus Challenge (optional)](#section-10)\n",
    "- [Section X: Individual Contribution Report (Mandatory)](#section-x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Section 1: Image Classification on CIFAR-100 (0 points)**\n",
    "\n",
    "The goal of this lab is to implement an image classification system using Convolutional Neural Networks (CNNs) that can identify objects from a set of classes in the [CIFAR-100 dataset](https://www.cs.toronto.edu/~kriz/cifar.html). You will implement and compare two different architectures: a simple two-layer network and a ConvNet based on the LeNet architecture.\n",
    "\n",
    "The CIFAR-100 dataset contains 32x32 pixel RGB images, categorized into 100 different classes. The dataset will be automatically downloaded and loaded using the code provided in this notebook.\n",
    "\n",
    "You will train and test your classification system using the entire CIFAR-100 dataset. Ensure that the test images are excluded from training to maintain a fair evaluation of the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Data loaders for CIFAR-100 are ready for use.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from PIL import Image\n",
    "from torchinfo import summary\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "\n",
    "# Define the transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  \n",
    "])\n",
    "\n",
    "# Load the CIFAR-100 training set\n",
    "train_set = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "# Load the CIFAR-100 test set\n",
    "test_set = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Create data loaders for the entire CIFAR-100 dataset\n",
    "train_data_loader = DataLoader(train_set, shuffle=True)\n",
    "test_data_loader = DataLoader(test_set, shuffle=False)\n",
    "\n",
    "# Define CIFAR-100 superclasses and their subclasses\n",
    "superclasses = {\n",
    "    'aquatic mammals': ['beaver', 'dolphin', 'otter', 'seal', 'whale'],\n",
    "    'fish': ['aquarium_fish', 'flatfish', 'ray', 'shark', 'trout'],\n",
    "    'flowers': ['orchid', 'poppy', 'rose', 'sunflower', 'tulip'],\n",
    "    'food containers': ['bottle', 'bowl', 'can', 'cup', 'plate'],\n",
    "    'fruit and vegetables': ['apple', 'mushroom', 'orange', 'pear', 'sweet_pepper'],\n",
    "    'household electrical devices': ['clock', 'keyboard', 'lamp', 'telephone', 'television'],\n",
    "    'household furniture': ['bed', 'chair', 'couch', 'table', 'wardrobe'],\n",
    "    'insects': ['bee', 'beetle', 'butterfly', 'caterpillar', 'cockroach'],\n",
    "    'large carnivores': ['bear', 'leopard', 'lion', 'tiger', 'wolf'],\n",
    "    'large man-made outdoor things': ['bridge', 'castle', 'house', 'road', 'skyscraper'],\n",
    "    'large natural outdoor scenes': ['cloud', 'forest', 'mountain', 'plain', 'sea'],\n",
    "    'large omnivores and herbivores': ['camel', 'cattle', 'chimpanzee', 'elephant', 'kangaroo'],\n",
    "    'medium-sized mammals': ['fox', 'porcupine', 'possum', 'raccoon', 'skunk'],\n",
    "    'non-insect invertebrates': ['crab', 'lobster', 'snail', 'spider', 'worm'],\n",
    "    'people': ['baby', 'boy', 'girl', 'man', 'woman'],\n",
    "    'reptiles': ['crocodile', 'dinosaur', 'lizard', 'snake', 'turtle'],\n",
    "    'small mammals': ['hamster', 'mouse', 'rabbit', 'shrew', 'squirrel'],\n",
    "    'trees': ['maple_tree', 'oak_tree', 'palm_tree', 'pine_tree', 'willow_tree'],\n",
    "    'vehicles 1': ['bicycle', 'bus', 'motorcycle', 'pickup_truck', 'train'],\n",
    "    'vehicles 2': ['lawn_mower', 'rocket', 'streetcar', 'tank', 'tractor']\n",
    "}\n",
    "\n",
    "# List of all CIFAR-100 classes\n",
    "classes = ('apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottle', \n",
    "           'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', 'can', 'castle', 'caterpillar', 'cattle',\n",
    "           'chair', 'chimpanzee', 'clock', 'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur',\n",
    "           'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', 'house', 'kangaroo', 'keyboard',\n",
    "           'lamp', 'lawn_mower', 'leopard', 'lion', 'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain',\n",
    "           'mouse', 'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear', 'pickup_truck', 'pine_tree',\n",
    "           'plain', 'plate', 'poppy', 'porcupine', 'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose', 'sea',\n",
    "           'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake', 'spider', 'squirrel', 'streetcar', 'sunflower', \n",
    "           'sweet_pepper', 'table', 'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout', 'tulip', \n",
    "           'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman', 'worm')\n",
    "\n",
    "# Create a mapping of class names to their indices\n",
    "class_to_idx = {cls_name: idx for idx, cls_name in enumerate(classes)}\n",
    "\n",
    "# Create a mapping of superclasses to their corresponding class indices\n",
    "superclass_to_indices = {supcls: [class_to_idx[cls] for cls in subclasses] for supcls, subclasses in superclasses.items()}\n",
    "\n",
    "print(\"Data loaders for CIFAR-100 are ready for use.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section-2\"></a>\n",
    "### **Section 2: Visualizing CIFAR-100 Classes and Subclasses (3 points)**\n",
    "\n",
    "In this section, you will implement a function to visualize the CIFAR-100 dataset, including **all** superclasses and their corresponding subclasses. Your implementation should provide a clear and organized overview of the dataset's diversity.\n",
    "\n",
    "You add the figure(s) to appendix of your report and refer to it in the main text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def visualize_cifar100_dataset(dataset, superclasses, subclass_indices):\n",
    "    \"\"\"\n",
    "    Visualize CIFAR-100 superclasses and their corresponding subclasses.\n",
    "\n",
    "    Parameters:\n",
    "    - dataset: The CIFAR-100 dataset\n",
    "    - superclasses: Dictionary of superclasses and their corresponding subclasses\n",
    "    - subclass_indices: Dictionary of superclasses and their corresponding indices\n",
    "    - num_images: Number of images to display per subclass (default is 1)\n",
    "    \"\"\"\n",
    "\n",
    "    # Loop through each superclass\n",
    "    for superclass, subclasses in superclasses.items():\n",
    "\n",
    "        num_subclasses = len(subclasses)\n",
    "        fig, axes = plt.subplots(1, num_subclasses, figsize=(8, 3))\n",
    "        fig.suptitle(superclass, fontsize=14)\n",
    "\n",
    "        # Superclass index\n",
    "        subclass_index = subclass_indices[superclass]\n",
    "        \n",
    "        # Loop through each subclass\n",
    "        for i, subclass_name in enumerate(subclasses):\n",
    "\n",
    "            # Randomly select an image\n",
    "            images = [(img, label) for img, label in dataset if label == subclass_index[i]]\n",
    "            image, _ = random.choice(images)\n",
    "            image = np.interp(image.numpy(), (-1, 1), (0, 255)).astype(np.uint8).transpose((1, 2, 0))\n",
    "            \n",
    "            ax = axes[i]\n",
    "            ax.imshow(image)\n",
    "            ax.set_title(subclass_name)\n",
    "            ax.axis('off')\n",
    "    \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# visualize_cifar100_dataset(train_set, superclasses, superclass_to_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section-3\"></a>\n",
    "### **Section 3: TwoLayerNet Architecture (2 points)**\n",
    "\n",
    "In this section, you will implement the architecture of a fully connected neural network called `TwoLayerNet`, consisting of two fully connected layers with a ReLU activation in between. The network accepts an input size of 3x32x32 (CIFAR-100 image), a specified hidden layer size, and the number of output classes. In the `__init__` method, define the first fully connected layer that maps the input size to the hidden size, and the second fully connected layer that maps the hidden size to the number of classes. \n",
    "\n",
    "Ensure to call the parent class constructor using `super(TwoLayerNet, self).__init__()`. In the `forward` method, flatten the input tensor, pass it through the first layer with ReLU activation, and then through the second layer to obtain the final scores.\n",
    "\n",
    "**Note:** You are allowed to modify the provided function definitions as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerNet(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        '''\n",
    "        Initializes the two-layer neural network model.\n",
    "\n",
    "        Args:\n",
    "            input_size (int): The size of the input features.\n",
    "            hidden_size (int): The size of the hidden layer.\n",
    "            num_classes (int): The number of classes in the dataset.\n",
    "        '''\n",
    "\n",
    "        super(TwoLayerNet, self).__init__()\n",
    "\n",
    "        self.layer1 = nn.Linear(input_size, hidden_size)\n",
    "        self.layer2 = nn.Linear(hidden_size, num_classes)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        Defines the forward pass of the neural network.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): The input tensor.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The output tensor.\n",
    "        '''\n",
    "\n",
    "        a1 = self.activation(self.layer1(self.flatten(x)))\n",
    "        output = self.layer2(a1)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section-4\"></a>\n",
    "### **Section 4: ConvNet Architecture (2 points)**\n",
    "\n",
    "In this section, you will implement a convolutional neural network inspired by the structure of [LeNet-5](https://ieeexplore.ieee.org/document/726791). The network processes color images using three convolutional layers followed by two fully connected layers. Since you need to feed color images into this network, determine the kernel size of the first convolutional layer. Additionally, calculate the number of trainable parameters in the \"F6\" layer, providing the calculation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters in the last layer: 10164\n",
      "Total trainable parameters in the model: 69656\n"
     ]
    }
   ],
   "source": [
    "class ConvNet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        '''\t\n",
    "        Initializes the convolutional neural network model.\n",
    "\n",
    "        Args:\n",
    "            None\n",
    "        '''\n",
    "\n",
    "        super(ConvNet, self).__init__()\n",
    "\n",
    "        # based on the LeNet-5 architecture\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5, stride=1, padding='valid') # 32x32x3 --> 28x28x6\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding='valid') # 14x14x6 --> 10x10x16\n",
    "\n",
    "        self.avg_pooling = nn.AvgPool2d(kernel_size=2) # 28x28x6 --> 14x14x6, 10x10x16 --> 5x5x16\n",
    "        self.activation = nn.Tanh()\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(in_features=400, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=84)\n",
    "        self.fc3 = nn.Linear(in_features=84, out_features=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        Defines the forward pass of the neural network.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): The input tensor.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The output tensor.\n",
    "        '''\n",
    "\n",
    "        a1 = self.avg_pooling(self.activation(self.conv1(x)))\n",
    "        a2 = self.avg_pooling(self.activation(self.conv2(a1)))\n",
    "        fc1 = self.fc1(self.flatten(a2))\n",
    "        fc2 = self.fc2(fc1)\n",
    "        output = self.fc3(fc2)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "model = ConvNet(num_classes=100)\n",
    "\n",
    "# number of trainable parameters in the model\n",
    "fc2_params = sum(p.numel() for p in model.fc2.parameters() if p.requires_grad)\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Trainable parameters in the last layer: {fc2_params}\")\n",
    "print(f\"Total trainable parameters in the model: {total_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section-5\"></a>\n",
    "### **Section 5: Preparation of Training (7 points)**\n",
    "\n",
    "In this section, you will create a custom dataset class to load the CIFAR-100 data, define a transform function for data augmentation, and set up an optimizer for training. While the previous section utilized the built-in CIFAR-100 class from `torchvision`, in practice, you often need to prepare datasets manually. Here, you will implement the `CIFAR100_loader` class to handle the dataset and use `DataLoader` to make it iterable. You will also define a transform function for data augmentation and an optimizer for updating the model's parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR100_loader(Dataset):\n",
    "    \n",
    "    def __init__(self, root, train=True, transform=None, download=False):\n",
    "        '''\n",
    "        Initializes the CIFAR-100 dataset loader.\n",
    "\n",
    "        Args:\n",
    "            root (str): The root directory to store the dataset.\n",
    "            train (bool): If True, loads the training data; otherwise, loads the test data.\n",
    "            transform (callable, optional): The data transformations to apply.\n",
    "            download (bool): If True, downloads the dataset if it is not already available.\n",
    "        '''\n",
    "\n",
    "        super(CIFAR100_loader, self).__init__()\n",
    "\n",
    "        self.data = torchvision.datasets.CIFAR100(root=root, train=train, download=download)\n",
    "        self.transform = transform if transform is not None else transforms.ToTensor()\n",
    "\n",
    "    def __len__(self):\n",
    "        '''\n",
    "        Returns the number of samples in the dataset.\n",
    "\n",
    "        Returns:\n",
    "            int: The number of samples in the dataset.\n",
    "        '''\n",
    "\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "        Retrieves a sample from the dataset at the specified index.\n",
    "\n",
    "        Args:\n",
    "            idx (int): The index of the sample to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            tuple: A tuple containing the image and label tensors.\n",
    "        '''\n",
    "\n",
    "        img, label = self.data[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_transforms():\n",
    "    '''\n",
    "    Creates the data transformations for the CIFAR-100 dataset.\n",
    "\n",
    "    Returns:\n",
    "        torchvision.transforms.Compose: The data transformations for the dataset.\n",
    "    '''\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "    return transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_optimizer(model, learning_rate=0.001):\n",
    "    '''\n",
    "    Creates an optimizer for the model.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The neural network model.\n",
    "        learning_rate (float): The learning rate for the optimizer.\n",
    "\n",
    "    Returns:\n",
    "        torch.optim.Adam: The optimizer for the model.\n",
    "    '''\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section-6\"></a>\n",
    "### **Section 6: Training the Networks (5 points)**\n",
    "\n",
    "In this section, you will complete the `train` function and use it to train both the `TwoLayerNet` and `ConvNet` models. You will use the custom `CIFAR100_loader`, transform function, and optimizer function that you implemented. The goal is to compare the performance of the two models on the CIFAR-100 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(net, testloader):\n",
    "    '''\n",
    "    Validates the model on the test dataset.\n",
    "\n",
    "    Args:\n",
    "        net (torch.nn.Module): The neural network model.\n",
    "        testloader (torch.utils.data.DataLoader): The data loader for the test dataset.\n",
    "\n",
    "    Returns:\n",
    "        float: The accuracy of the model on the test dataset.\n",
    "    '''\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    net.eval()\n",
    "\n",
    "    # Determine the device to run the model on\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    # Disable gradient computation\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # Iterate over the test dataset\n",
    "        for inputs, labels in testloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = net(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy of the network on the test images: {accuracy:.2f} %')\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_per_class(net, testloader, classes):\n",
    "    '''\n",
    "    Validates the model on the test dataset per class.\n",
    "\n",
    "    Args:\n",
    "        net (torch.nn.Module): The neural network model.\n",
    "        testloader (torch.utils.data.DataLoader): The data loader for the test dataset.\n",
    "        classes (tuple): The tuple of class names.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    '''\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    net.eval()\n",
    "\n",
    "    # Determine the device to run the model on\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    class_correct = [0. for _ in range(len(classes))]\n",
    "    class_total = [0. for _ in range(len(classes))]\n",
    "\n",
    "    # Disable gradient computation\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # Iterate over the test dataset\n",
    "        for inputs, labels in testloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = net(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_predictions = (predicted == labels).squeeze()\n",
    "\n",
    "            for i in range(len(labels)):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += correct_predictions[i].item()\n",
    "                class_total[label] += 1\n",
    "\n",
    "    for i, class_name in enumerate(classes):\n",
    "        accuracy = 100 * class_correct[i] / class_total[i] if class_total[i] > 0 else 0\n",
    "        print(f'Accuracy of {class_name:5s} : {accuracy:.2f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_loader, criterion, optimizer, epochs=100):\n",
    "    '''\n",
    "    Trains the neural network model.\n",
    "\n",
    "    Args:\n",
    "        net (torch.nn.Module): The neural network model.\n",
    "        train_loader (torch.utils.data.DataLoader): The data loader for the training dataset.\n",
    "        criterion (torch.nn.Module): The loss function.\n",
    "        optimizer (torch.optim.Optimizer): The optimizer for the model.\n",
    "        epochs (int): The number of epochs to train the model.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    '''\n",
    "    net.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        total_loss = 0.0\n",
    "        correct, total = 0, 0\n",
    "\n",
    "        for data in train_loader:\n",
    "\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(net.device), labels.to(net.device)         \n",
    "\n",
    "            # Forward and loss\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backpropagation and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Sum losses of each batch\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            with torch.no_grad():\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        accuracy = 100 * correct / total\n",
    "\n",
    "        # Print epoch statistics\n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {total_loss / len(train_loader):.4f}, Accuracy: {accuracy:.2f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, initialize the datasets and data loaders for both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "root = './data'\n",
    "\n",
    "# set the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# set the transform\n",
    "transform = create_transforms()\n",
    "\n",
    "# create the data loaders\n",
    "train_dataset = CIFAR100_loader(root=root, train=True, transform=transform, download=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "test_dataset = CIFAR100_loader(root=root, train=False, transform=transform, download=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, train the TwoLayerNet model on the CIFAR-100 dataset using the training data loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started...\n",
      "Epoch [1/20], Loss: 4.0052, Accuracy: 9.28 %\n",
      "Epoch [2/20], Loss: 3.7408, Accuracy: 13.12 %\n",
      "Epoch [3/20], Loss: 3.6355, Accuracy: 15.06 %\n",
      "Epoch [4/20], Loss: 3.5784, Accuracy: 16.13 %\n",
      "Epoch [5/20], Loss: 3.5347, Accuracy: 17.00 %\n",
      "Epoch [6/20], Loss: 3.5124, Accuracy: 17.32 %\n",
      "Epoch [7/20], Loss: 3.4770, Accuracy: 18.03 %\n",
      "Epoch [8/20], Loss: 3.4623, Accuracy: 18.33 %\n",
      "Epoch [9/20], Loss: 3.4514, Accuracy: 18.50 %\n",
      "Epoch [10/20], Loss: 3.4389, Accuracy: 18.64 %\n",
      "Epoch [11/20], Loss: 3.4308, Accuracy: 18.77 %\n",
      "Epoch [12/20], Loss: 3.4278, Accuracy: 18.89 %\n",
      "Epoch [13/20], Loss: 3.4180, Accuracy: 19.10 %\n",
      "Epoch [14/20], Loss: 3.4151, Accuracy: 19.10 %\n",
      "Epoch [15/20], Loss: 3.3991, Accuracy: 19.17 %\n",
      "Epoch [16/20], Loss: 3.4023, Accuracy: 19.43 %\n",
      "Epoch [17/20], Loss: 3.3870, Accuracy: 19.42 %\n",
      "Epoch [18/20], Loss: 3.3872, Accuracy: 19.40 %\n",
      "Epoch [19/20], Loss: 3.3792, Accuracy: 19.95 %\n",
      "Epoch [20/20], Loss: 3.3758, Accuracy: 19.79 %\n",
      "Validating model on test data:\n",
      "Accuracy of the network on the test images: 19.36 %\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Create the model\n",
    "two_layer_net = TwoLayerNet(input_size=32 * 32 * 3, hidden_size=128, num_classes=100)\n",
    "\n",
    "# Device to train the model on\n",
    "two_layer_net.to(device)\n",
    "two_layer_net.device = device\n",
    "\n",
    "# create the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion = criterion.to(two_layer_net.device)\n",
    "\n",
    "# Optimizer for the model\n",
    "optimizer_two_layer_net = create_optimizer(two_layer_net, learning_rate=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "print(\"Training started...\")\n",
    "train(two_layer_net, train_loader, criterion, optimizer_two_layer_net, epochs=epochs)\n",
    "\n",
    "print(\"Validating model on test data:\")\n",
    "accuracy = validate(two_layer_net, test_loader)\n",
    "\n",
    "# print(\"Per-class accuracy for model:\")\n",
    "# validate_per_class(two_layer_net, test_loader, classes)\n",
    "\n",
    "torch.save(two_layer_net.state_dict(), 'two_layer_net.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, train the ConvNet model on the CIFAR-100 dataset using the training data loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started...\n",
      "Epoch [1/20], Loss: 4.0289, Accuracy: 9.03 %\n",
      "Epoch [2/20], Loss: 3.7973, Accuracy: 12.63 %\n",
      "Epoch [3/20], Loss: 3.7190, Accuracy: 13.75 %\n",
      "Epoch [4/20], Loss: 3.6771, Accuracy: 14.50 %\n",
      "Epoch [5/20], Loss: 3.6375, Accuracy: 15.23 %\n",
      "Epoch [6/20], Loss: 3.5942, Accuracy: 15.56 %\n",
      "Epoch [7/20], Loss: 3.5461, Accuracy: 16.41 %\n",
      "Epoch [8/20], Loss: 3.4936, Accuracy: 17.16 %\n",
      "Epoch [9/20], Loss: 3.4433, Accuracy: 18.21 %\n",
      "Epoch [10/20], Loss: 3.4011, Accuracy: 19.07 %\n",
      "Epoch [11/20], Loss: 3.3748, Accuracy: 19.40 %\n",
      "Epoch [12/20], Loss: 3.3475, Accuracy: 20.17 %\n",
      "Epoch [13/20], Loss: 3.3273, Accuracy: 20.41 %\n",
      "Epoch [14/20], Loss: 3.3151, Accuracy: 20.98 %\n",
      "Epoch [15/20], Loss: 3.3000, Accuracy: 21.17 %\n",
      "Epoch [16/20], Loss: 3.2837, Accuracy: 21.37 %\n",
      "Epoch [17/20], Loss: 3.2749, Accuracy: 21.53 %\n",
      "Epoch [18/20], Loss: 3.2609, Accuracy: 21.69 %\n",
      "Epoch [19/20], Loss: 3.2490, Accuracy: 22.11 %\n",
      "Epoch [20/20], Loss: 3.2442, Accuracy: 22.28 %\n",
      "Validating model on test data:\n",
      "Accuracy of the network on the test images: 22.26 %\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Create the model\n",
    "conv_net = ConvNet(num_classes=100)\n",
    "\n",
    "# Device to train the model on\n",
    "conv_net.to(device)\n",
    "conv_net.device = device\n",
    "\n",
    "# create the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion = criterion.to(conv_net.device)\n",
    "\n",
    "# Optimizer for the model\n",
    "optimizer_conv_net = create_optimizer(conv_net, learning_rate=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "print(\"Training started...\")\n",
    "train(conv_net, train_loader, criterion, optimizer_conv_net, epochs=epochs)\n",
    "\n",
    "print(\"Validating model on test data:\")\n",
    "accuracy = validate(conv_net, test_loader)\n",
    "\n",
    "# print(\"Per-class accuracy for model:\")\n",
    "# validate_per_class(conv_net, test_loader, classes)\n",
    "\n",
    "torch.save(conv_net.state_dict(), 'conv_net.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section-7\"></a>\n",
    "### **Section 7: Setting Up the Hyperparameters (14 points)**\n",
    "\n",
    "In this section, you will experiment with both the `ConvNet` and `TwoLayerNet` models by setting up and tuning the hyperparameters to achieve the highest possible accuracy. You have the flexibility to modify the training process, including the `train` function, `DataLoader`, `transform` functions, and optimizer as needed.\n",
    "\n",
    "1. Adjust the hyperparameters, including learning rate, batch size, number of epochs, optimizer, weight decay, and transform function to improve the performance of both networks. Modify the training procedure and architecture as necessary. You can also add components like Batch Normalization layers.\n",
    "2. Add two more layers to both `TwoLayerNet` and `ConvNet`. You can decide the size and placement of these layers. Evaluate if these changes result in higher performance and explain your findings.\n",
    "3. Show the final results and describe the modifications made to enhance performance. Discuss the impact of hyperparameter tuning on both `TwoLayerNet` and `ConvNet`.\n",
    "4. Compare the two networks in terms of architecture, performance, and learning rates. Provide a detailed explanation of the differences observed.\n",
    "\n",
    "**Note:** Do not use external pre-trained networks and limit additional convolutional layers to a maximum of three beyond the original architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps followed:\n",
    "\n",
    "1. Created new models (TwoLayerNetWithBN and ConvNetWithBN) by adding batch normalization layers to the original architectures.\n",
    "2. Tuned the hyperparameters for the new models using the Optuna package. \n",
    "3. Found the best learning rate, batch size, number of epochs, optimizer, alpha value for weight decay and a scheduler to accomodate the learning rate properly. The optimizer also had its own parameters optimized. Also added a small validatition dataset to analyze after each epoch. \n",
    "4. Trained these two new models using the best hyperparameters found to see how much they improved over the originals.\n",
    "5. Created two new models (TwoLayerNetImproved and ConvNetImproved), based on the original ones, by adding more layers (2 Linear or 3 Convolutional), batch normalization, max pooling, dropout, skip connections and a better activation function.\n",
    "6. Trained these final models using similar hyperparameters to the ones found before to see how much they improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create the network models with batch normalization ###\n",
    "\n",
    "class TwoLayerNetWithBN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        '''\n",
    "        Initializes the two-layer neural network model.\n",
    "\n",
    "        Args:\n",
    "            input_size (int): The size of the input features.\n",
    "            hidden_size (int): The size of the hidden layer.\n",
    "            num_classes (int): The number of classes in the dataset.\n",
    "        '''\n",
    "\n",
    "        super(TwoLayerNetWithBN, self).__init__()\n",
    "\n",
    "        self.layer1 = nn.Linear(input_size, hidden_size)\n",
    "        self.layer2 = nn.Linear(hidden_size, num_classes)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.batch_norm1 = nn.BatchNorm1d(hidden_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        Defines the forward pass of the neural network.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): The input tensor.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The output tensor.\n",
    "        '''\n",
    "\n",
    "        a1 = self.activation(self.batch_norm1(self.layer1(self.flatten(x))))\n",
    "        output = self.layer2(a1)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "\n",
    "class ConvNetWithBN(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        '''\t\n",
    "        Initializes the convolutional neural network model.\n",
    "\n",
    "        Args:\n",
    "            None\n",
    "        '''\n",
    "\n",
    "        super(ConvNetWithBN, self).__init__()\n",
    "\n",
    "        # based on the LeNet-5 architecture\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5, stride=1, padding='valid') # 32x32x3 --> 28x28x6\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding='valid') # 14x14x6 --> 10x10x16\n",
    "\n",
    "        self.avg_pooling = nn.AvgPool2d(kernel_size=2) # 28x28x6 --> 14x14x6, 10x10x16 --> 5x5x16\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "        self.batch_norm1 = nn.BatchNorm2d(6)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(16)\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(in_features=400, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=84)\n",
    "        self.fc3 = nn.Linear(in_features=84, out_features=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        Defines the forward pass of the neural network.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): The input tensor.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The output tensor.\n",
    "        '''\n",
    "\n",
    "        a1 = self.avg_pooling(self.activation(self.batch_norm1(self.conv1(x))))\n",
    "        a2 = self.avg_pooling(self.activation(self.batch_norm2(self.conv2(a1))))\n",
    "        fc1 = self.fc1(self.flatten(a2))\n",
    "        fc2 = self.fc2(fc1)\n",
    "        output = self.fc3(fc2)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tune the hyperparameters ###\n",
    "\n",
    "import optuna\n",
    "\n",
    "def evaluate_on_dataset(net, dataLoader, include_loss=False):\n",
    "    '''\n",
    "    Validates the model on the test dataset.\n",
    "\n",
    "    Args:\n",
    "        net (torch.nn.Module): The neural network model.\n",
    "        dataLoader (torch.utils.data.DataLoader): The data loader for the test dataset.\n",
    "\n",
    "    Returns:\n",
    "        float: The accuracy of the model on the test dataset.\n",
    "    '''\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    net.eval()\n",
    "\n",
    "    # Determine the device to run the model on\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    if include_loss:\n",
    "        val_loss = 0.0\n",
    "\n",
    "    # Disable gradient computation\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # Iterate over the test dataset\n",
    "        for data in dataLoader:\n",
    "\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = net(inputs)\n",
    "\n",
    "            if include_loss:\n",
    "                val_loss += criterion(outputs, labels).item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "\n",
    "    if include_loss:\n",
    "        return accuracy, val_loss\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "# Training function\n",
    "def train_and_evaluate(model, train_loader, val_loader, test_loader, criterion, optimizer, scheduler, epochs=10):\n",
    "    \n",
    "    for _ in range(epochs):\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for data in train_loader:\n",
    "\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(model.device), labels.to(model.device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        if scheduler and isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "            _, val_loss = evaluate_on_dataset(model, val_loader, include_loss=True)\n",
    "            scheduler.step(val_loss / len(val_loader))\n",
    "        elif scheduler:\n",
    "            scheduler.step()\n",
    "    \n",
    "    # Evaluate the model on the test set\n",
    "    return evaluate_on_dataset(model, test_loader)\n",
    "\n",
    "# Optuna Objective function\n",
    "def objective(trial, model_type):\n",
    "    # Hyperparameters to be tuned\n",
    "    learning_rate = trial.suggest_categorical('learning_rate', [1e-4, 1e-3, 1e-2])\n",
    "    weight_decay = trial.suggest_categorical('weight_decay', [1e-5, 1e-4, 1e-3])\n",
    "    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])\n",
    "    epochs = trial.suggest_int('epochs', 5, 25, step=5)\n",
    "\n",
    "    # Set up the device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    if model_type == 'conv_net':\n",
    "        model = ConvNetWithBN(100)\n",
    "    elif model_type == 'two_layer_net':\n",
    "        hidden_size = trial.suggest_int('hidden_size', 128, 1024, step=128)\n",
    "        model = TwoLayerNetWithBN(32 * 32 * 3, hidden_size, 100)\n",
    "\n",
    "    model.to(device)\n",
    "    model.device = device\n",
    "\n",
    "    # set the transform\n",
    "    transform = create_transforms()\n",
    "\n",
    "    # load CIFAR-100 data\n",
    "    train_dataset = CIFAR100_loader(root='./data', train=True, transform=transform, download=True)\n",
    "    test_dataset = CIFAR100_loader(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "    train_size = int(0.9 * len(train_dataset))\n",
    "    train_subset, val_subset = random_split(train_dataset, [train_size, len(train_dataset) - train_size])\n",
    "\n",
    "    # set the data loaders\n",
    "    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "    validation_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    # Learning rate scheduler options\n",
    "    scheduler_type = trial.suggest_categorical('scheduler_type', ['None', 'StepLR', 'ReduceLROnPlateau'])\n",
    "\n",
    "    if scheduler_type == 'StepLR':\n",
    "        step_size = trial.suggest_categorical('step_size', [10, 15])\n",
    "        gamma = trial.suggest_float('gamma', 0.1, 0.9)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "    elif scheduler_type == 'ReduceLROnPlateau':\n",
    "        patience = trial.suggest_categorical('patience', [5, 10])\n",
    "        lr_factor = trial.suggest_float('lr_factor', 0.1, 0.9)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=lr_factor, patience=patience)\n",
    "    else:\n",
    "        scheduler = None\n",
    "\n",
    "    # Train and evaluate the model\n",
    "    accuracy = train_and_evaluate(model, train_loader, validation_loader, test_loader, criterion, optimizer, scheduler, epochs)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Optimize for TwoLayerNet ###\n",
    "\n",
    "two_layer_study = optuna.create_study(direction='maximize')\n",
    "two_layer_study.optimize(lambda trial: objective(trial, 'two_layer_net'), n_trials=40)\n",
    "\n",
    "best_params_two_layer = two_layer_study.best_params\n",
    "print(f\"Best hyperparameters for TwoLayerNet: {best_params_two_layer}\")\n",
    "\n",
    "# Best hyperparameters for TwoLayerNet: {'learning_rate': 0.001, 'weight_decay': 1e-05, 'batch_size': 64, 'epochs': 20, 'hidden_size': 768, 'scheduler_type': 'ReduceLROnPlateau', 'patience': 5, 'lr_factor': 0.30025677479207347}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Optimize for ConvNet ###\n",
    "\n",
    "conv_net_study = optuna.create_study(direction='maximize')\n",
    "conv_net_study.optimize(lambda trial: objective(trial, 'conv_net'), n_trials=40)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params_conv_net = conv_net_study.best_params\n",
    "print(f\"Best hyperparameters for ConvNet: {best_params_conv_net}\")\n",
    "\n",
    "# Best hyperparameters for ConvNet: {'learning_rate': 0.001, 'weight_decay': 0.0001, 'batch_size': 64, 'epochs': 25, 'scheduler_type': 'ReduceLROnPlateau', 'patience': 5, 'lr_factor': 0.28991373146096105}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "### Train both models with the best hyperparameters found ###\n",
    "\n",
    "root = './data'\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "transform = create_transforms()\n",
    "\n",
    "train_dataset = CIFAR100_loader(root=root, train=True, transform=transform, download=True)\n",
    "test_dataset = CIFAR100_loader(root=root, train=False, transform=transform, download=True)\n",
    "\n",
    "train_size = int(0.9 * len(train_dataset))\n",
    "train_subset, val_subset = random_split(train_dataset, [train_size, len(train_dataset) - train_size])\n",
    "\n",
    "\n",
    "def new_create_optimizer(model, learning_rate=0.001, weight_decay=1e-4, lr_factor=0.1, patience=5):\n",
    "    '''\n",
    "    Creates an optimizer for the model.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The neural network model.\n",
    "        learning_rate (float): The learning rate for the optimizer.\n",
    "\n",
    "    Returns:\n",
    "        torch.optim.Adam: The optimizer for the model.\n",
    "    '''\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=lr_factor, patience=patience)\n",
    "    return optimizer, scheduler\n",
    "\n",
    "def new_validate(net, dataLoader, validation=False):\n",
    "    '''\n",
    "    Validates the model on the test dataset.\n",
    "\n",
    "    Args:\n",
    "        net (torch.nn.Module): The neural network model.\n",
    "        dataLoader (torch.utils.data.DataLoader): The data loader for the test dataset.\n",
    "\n",
    "    Returns:\n",
    "        float: The accuracy of the model on the test dataset.\n",
    "    '''\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    net.eval()\n",
    "\n",
    "    # Determine the device to run the model on\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    if validation:\n",
    "        val_loss = 0.0\n",
    "\n",
    "    # Disable gradient computation\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # Iterate over the test dataset\n",
    "        for inputs, labels in dataLoader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = net(inputs)\n",
    "            if validation:\n",
    "                val_loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "\n",
    "    if validation:\n",
    "        return accuracy, val_loss\n",
    "\n",
    "    print(f'Accuracy of the network on the test images: {accuracy:.2f} %')\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "def new_train(net, train_loader, validation_loader, criterion, optimizer, scheduler, epochs=100):\n",
    "    '''\n",
    "    Trains the neural network model.\n",
    "\n",
    "    Args:\n",
    "        net (torch.nn.Module): The neural network model.\n",
    "        train_loader (torch.utils.data.DataLoader): The data loader for the training dataset.\n",
    "        criterion (torch.nn.Module): The loss function.\n",
    "        optimizer (torch.optim.Optimizer): The optimizer for the model.\n",
    "        scheduler (torch.optim.lr_scheduler): The learning rate scheduler.\n",
    "        epochs (int): The number of epochs to train the model.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    '''\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        net.train()\n",
    "\n",
    "        total_loss = 0.0\n",
    "        correct, total = 0, 0\n",
    "\n",
    "        for data in train_loader:\n",
    "\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(net.device), labels.to(net.device)         \n",
    "\n",
    "            # Forward and loss\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backpropagation and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Sum losses of each batch\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            with torch.no_grad():\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        accuracy = 100 * correct / total        \n",
    "\n",
    "        # Now updating the learning rate\n",
    "        if scheduler and isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "            val_accuracy, val_loss = new_validate(net, validation_loader, validation=True)\n",
    "            scheduler.step(val_loss / len(validation_loader))\n",
    "        elif scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "        # Print epoch statistics\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        print(f\"\"\"Epoch [{epoch + 1}/{epochs}], Loss: {total_loss / len(train_loader):.4f}, Accuracy: {accuracy:.2f}%, LR: {current_lr:.5f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started...\n",
      "Epoch [1/20], Loss: 3.9674, Accuracy: 10.12%, LR: 0.00100, Val Loss: 297.1820, Val Accuracy: 13.06%\n",
      "Epoch [2/20], Loss: 3.6946, Accuracy: 13.99%, LR: 0.00100, Val Loss: 284.0526, Val Accuracy: 16.20%\n",
      "Epoch [3/20], Loss: 3.5801, Accuracy: 16.19%, LR: 0.00100, Val Loss: 278.7106, Val Accuracy: 17.20%\n",
      "Epoch [4/20], Loss: 3.4849, Accuracy: 17.88%, LR: 0.00100, Val Loss: 274.2779, Val Accuracy: 18.32%\n",
      "Epoch [5/20], Loss: 3.4292, Accuracy: 18.61%, LR: 0.00100, Val Loss: 271.1739, Val Accuracy: 19.26%\n",
      "Epoch [6/20], Loss: 3.3819, Accuracy: 19.64%, LR: 0.00100, Val Loss: 266.9506, Val Accuracy: 20.32%\n",
      "Epoch [7/20], Loss: 3.3354, Accuracy: 20.70%, LR: 0.00100, Val Loss: 262.4469, Val Accuracy: 21.52%\n",
      "Epoch [8/20], Loss: 3.2959, Accuracy: 21.54%, LR: 0.00100, Val Loss: 261.2748, Val Accuracy: 21.92%\n",
      "Epoch [9/20], Loss: 3.2645, Accuracy: 21.95%, LR: 0.00100, Val Loss: 261.3083, Val Accuracy: 21.92%\n",
      "Epoch [10/20], Loss: 3.2397, Accuracy: 22.55%, LR: 0.00100, Val Loss: 258.2298, Val Accuracy: 23.12%\n",
      "Epoch [11/20], Loss: 3.2150, Accuracy: 22.80%, LR: 0.00100, Val Loss: 255.5064, Val Accuracy: 23.16%\n",
      "Epoch [12/20], Loss: 3.1967, Accuracy: 23.07%, LR: 0.00100, Val Loss: 256.4916, Val Accuracy: 22.84%\n",
      "Epoch [13/20], Loss: 3.1694, Accuracy: 23.77%, LR: 0.00100, Val Loss: 254.2441, Val Accuracy: 24.34%\n",
      "Epoch [14/20], Loss: 3.1597, Accuracy: 23.99%, LR: 0.00100, Val Loss: 255.3390, Val Accuracy: 24.04%\n",
      "Epoch [15/20], Loss: 3.1358, Accuracy: 24.14%, LR: 0.00100, Val Loss: 252.1355, Val Accuracy: 24.66%\n",
      "Epoch [16/20], Loss: 3.1223, Accuracy: 24.83%, LR: 0.00100, Val Loss: 250.3074, Val Accuracy: 25.22%\n",
      "Epoch [17/20], Loss: 3.1085, Accuracy: 24.68%, LR: 0.00100, Val Loss: 249.5604, Val Accuracy: 25.06%\n",
      "Epoch [18/20], Loss: 3.0943, Accuracy: 25.33%, LR: 0.00100, Val Loss: 249.2911, Val Accuracy: 25.16%\n",
      "Epoch [19/20], Loss: 3.0798, Accuracy: 25.49%, LR: 0.00100, Val Loss: 248.4296, Val Accuracy: 25.00%\n",
      "Epoch [20/20], Loss: 3.0713, Accuracy: 25.58%, LR: 0.00100, Val Loss: 248.1526, Val Accuracy: 25.46%\n",
      "Validating model on test data:\n",
      "Accuracy of the network on the test images: 25.25 %\n",
      "Per-class accuracy for model:\n",
      "Accuracy of apple : 49.00 %\n",
      "Accuracy of aquarium_fish : 53.00 %\n",
      "Accuracy of baby  : 18.00 %\n",
      "Accuracy of bear  : 7.00 %\n",
      "Accuracy of beaver : 18.00 %\n",
      "Accuracy of bed   : 14.00 %\n",
      "Accuracy of bee   : 27.00 %\n",
      "Accuracy of beetle : 16.00 %\n",
      "Accuracy of bicycle : 24.00 %\n",
      "Accuracy of bottle : 29.00 %\n",
      "Accuracy of bowl  : 2.00 %\n",
      "Accuracy of boy   : 8.00 %\n",
      "Accuracy of bridge : 8.00 %\n",
      "Accuracy of bus   : 21.00 %\n",
      "Accuracy of butterfly : 15.00 %\n",
      "Accuracy of camel : 12.00 %\n",
      "Accuracy of can   : 18.00 %\n",
      "Accuracy of castle : 48.00 %\n",
      "Accuracy of caterpillar : 19.00 %\n",
      "Accuracy of cattle : 11.00 %\n",
      "Accuracy of chair : 60.00 %\n",
      "Accuracy of chimpanzee : 56.00 %\n",
      "Accuracy of clock : 9.00 %\n",
      "Accuracy of cloud : 41.00 %\n",
      "Accuracy of cockroach : 45.00 %\n",
      "Accuracy of couch : 11.00 %\n",
      "Accuracy of crab  : 9.00 %\n",
      "Accuracy of crocodile : 25.00 %\n",
      "Accuracy of cup   : 34.00 %\n",
      "Accuracy of dinosaur : 16.00 %\n",
      "Accuracy of dolphin : 21.00 %\n",
      "Accuracy of elephant : 15.00 %\n",
      "Accuracy of flatfish : 12.00 %\n",
      "Accuracy of forest : 30.00 %\n",
      "Accuracy of fox   : 18.00 %\n",
      "Accuracy of girl  : 20.00 %\n",
      "Accuracy of hamster : 30.00 %\n",
      "Accuracy of house : 37.00 %\n",
      "Accuracy of kangaroo : 14.00 %\n",
      "Accuracy of keyboard : 10.00 %\n",
      "Accuracy of lamp  : 19.00 %\n",
      "Accuracy of lawn_mower : 45.00 %\n",
      "Accuracy of leopard : 18.00 %\n",
      "Accuracy of lion  : 31.00 %\n",
      "Accuracy of lizard : 10.00 %\n",
      "Accuracy of lobster : 10.00 %\n",
      "Accuracy of man   : 6.00 %\n",
      "Accuracy of maple_tree : 26.00 %\n",
      "Accuracy of motorcycle : 30.00 %\n",
      "Accuracy of mountain : 15.00 %\n",
      "Accuracy of mouse : 4.00 %\n",
      "Accuracy of mushroom : 14.00 %\n",
      "Accuracy of oak_tree : 70.00 %\n",
      "Accuracy of orange : 55.00 %\n",
      "Accuracy of orchid : 37.00 %\n",
      "Accuracy of otter : 0.00 %\n",
      "Accuracy of palm_tree : 38.00 %\n",
      "Accuracy of pear  : 21.00 %\n",
      "Accuracy of pickup_truck : 30.00 %\n",
      "Accuracy of pine_tree : 20.00 %\n",
      "Accuracy of plain : 65.00 %\n",
      "Accuracy of plate : 26.00 %\n",
      "Accuracy of poppy : 28.00 %\n",
      "Accuracy of porcupine : 37.00 %\n",
      "Accuracy of possum : 13.00 %\n",
      "Accuracy of rabbit : 3.00 %\n",
      "Accuracy of raccoon : 8.00 %\n",
      "Accuracy of ray   : 22.00 %\n",
      "Accuracy of road  : 62.00 %\n",
      "Accuracy of rocket : 39.00 %\n",
      "Accuracy of rose  : 27.00 %\n",
      "Accuracy of sea   : 57.00 %\n",
      "Accuracy of seal  : 4.00 %\n",
      "Accuracy of shark : 34.00 %\n",
      "Accuracy of shrew : 13.00 %\n",
      "Accuracy of skunk : 38.00 %\n",
      "Accuracy of skyscraper : 48.00 %\n",
      "Accuracy of snail : 14.00 %\n",
      "Accuracy of snake : 12.00 %\n",
      "Accuracy of spider : 21.00 %\n",
      "Accuracy of squirrel : 12.00 %\n",
      "Accuracy of streetcar : 12.00 %\n",
      "Accuracy of sunflower : 61.00 %\n",
      "Accuracy of sweet_pepper : 31.00 %\n",
      "Accuracy of table : 6.00 %\n",
      "Accuracy of tank  : 34.00 %\n",
      "Accuracy of telephone : 22.00 %\n",
      "Accuracy of television : 23.00 %\n",
      "Accuracy of tiger : 22.00 %\n",
      "Accuracy of tractor : 14.00 %\n",
      "Accuracy of train : 21.00 %\n",
      "Accuracy of trout : 29.00 %\n",
      "Accuracy of tulip : 8.00 %\n",
      "Accuracy of turtle : 8.00 %\n",
      "Accuracy of wardrobe : 68.00 %\n",
      "Accuracy of whale : 46.00 %\n",
      "Accuracy of willow_tree : 26.00 %\n",
      "Accuracy of wolf  : 20.00 %\n",
      "Accuracy of woman : 9.00 %\n",
      "Accuracy of worm  : 20.00 %\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "epochs = 20\n",
    "hidden_size = 768\n",
    "learning_rate = 0.001\n",
    "weight_decay = 1e-5\n",
    "lr_factor = 0.3\n",
    "patience = 5\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "validation_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "two_layer_net = TwoLayerNetWithBN(input_size=32 * 32 * 3, hidden_size=hidden_size, num_classes=100)\n",
    "two_layer_net.to(device)\n",
    "two_layer_net.device = device\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion = criterion.to(two_layer_net.device)\n",
    "\n",
    "optimizer_two_layer_net, scheduler = new_create_optimizer(two_layer_net, learning_rate=learning_rate, weight_decay=weight_decay, lr_factor=lr_factor, patience=patience)\n",
    "\n",
    "print(\"Training started...\")\n",
    "new_train(two_layer_net, train_loader, validation_loader, criterion, optimizer_two_layer_net, scheduler, epochs=epochs)\n",
    "\n",
    "print(\"Validating model on test data:\")\n",
    "accuracy = new_validate(two_layer_net, test_loader)\n",
    "\n",
    "print(\"Per-class accuracy for model:\")\n",
    "validate_per_class(two_layer_net, test_loader, classes)\n",
    "\n",
    "torch.save(two_layer_net.state_dict(), 'two_layer_net_with_bn.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started...\n",
      "Epoch [1/25], Loss: 4.0381, Accuracy: 8.95%, LR: 0.00100, Val Loss: 153.8674, Val Accuracy: 11.44%\n",
      "Epoch [2/25], Loss: 3.7549, Accuracy: 13.48%, LR: 0.00100, Val Loss: 147.9512, Val Accuracy: 14.54%\n",
      "Epoch [3/25], Loss: 3.6521, Accuracy: 14.73%, LR: 0.00100, Val Loss: 145.7878, Val Accuracy: 14.98%\n",
      "Epoch [4/25], Loss: 3.5639, Accuracy: 16.37%, LR: 0.00100, Val Loss: 141.8031, Val Accuracy: 17.06%\n",
      "Epoch [5/25], Loss: 3.5000, Accuracy: 17.65%, LR: 0.00100, Val Loss: 140.7079, Val Accuracy: 17.82%\n",
      "Epoch [6/25], Loss: 3.4556, Accuracy: 18.46%, LR: 0.00100, Val Loss: 140.2347, Val Accuracy: 18.48%\n",
      "Epoch [7/25], Loss: 3.4115, Accuracy: 19.09%, LR: 0.00100, Val Loss: 137.7396, Val Accuracy: 18.76%\n",
      "Epoch [8/25], Loss: 3.3860, Accuracy: 19.64%, LR: 0.00100, Val Loss: 136.2262, Val Accuracy: 18.96%\n",
      "Epoch [9/25], Loss: 3.3580, Accuracy: 19.90%, LR: 0.00100, Val Loss: 135.5563, Val Accuracy: 20.04%\n",
      "Epoch [10/25], Loss: 3.3266, Accuracy: 20.57%, LR: 0.00100, Val Loss: 134.7723, Val Accuracy: 20.32%\n",
      "Epoch [11/25], Loss: 3.3080, Accuracy: 20.96%, LR: 0.00100, Val Loss: 134.9772, Val Accuracy: 20.44%\n",
      "Epoch [12/25], Loss: 3.2879, Accuracy: 21.22%, LR: 0.00100, Val Loss: 134.3416, Val Accuracy: 20.72%\n",
      "Epoch [13/25], Loss: 3.2807, Accuracy: 21.53%, LR: 0.00100, Val Loss: 132.9971, Val Accuracy: 21.02%\n",
      "Epoch [14/25], Loss: 3.2629, Accuracy: 21.79%, LR: 0.00100, Val Loss: 132.3060, Val Accuracy: 21.80%\n",
      "Epoch [15/25], Loss: 3.2495, Accuracy: 22.10%, LR: 0.00100, Val Loss: 132.4176, Val Accuracy: 20.76%\n",
      "Epoch [16/25], Loss: 3.2405, Accuracy: 22.16%, LR: 0.00100, Val Loss: 131.8549, Val Accuracy: 21.24%\n",
      "Epoch [17/25], Loss: 3.2335, Accuracy: 22.26%, LR: 0.00100, Val Loss: 132.7825, Val Accuracy: 21.48%\n",
      "Epoch [18/25], Loss: 3.2151, Accuracy: 22.69%, LR: 0.00100, Val Loss: 132.4786, Val Accuracy: 20.96%\n",
      "Epoch [19/25], Loss: 3.2069, Accuracy: 22.89%, LR: 0.00100, Val Loss: 132.7291, Val Accuracy: 21.54%\n",
      "Epoch [20/25], Loss: 3.2033, Accuracy: 23.22%, LR: 0.00100, Val Loss: 129.6742, Val Accuracy: 21.60%\n",
      "Epoch [21/25], Loss: 3.1900, Accuracy: 23.21%, LR: 0.00100, Val Loss: 130.8617, Val Accuracy: 22.46%\n",
      "Epoch [22/25], Loss: 3.1846, Accuracy: 23.20%, LR: 0.00100, Val Loss: 129.2543, Val Accuracy: 22.84%\n",
      "Epoch [23/25], Loss: 3.1721, Accuracy: 23.53%, LR: 0.00100, Val Loss: 128.5155, Val Accuracy: 23.72%\n",
      "Epoch [24/25], Loss: 3.1656, Accuracy: 23.66%, LR: 0.00100, Val Loss: 129.2042, Val Accuracy: 22.76%\n",
      "Epoch [25/25], Loss: 3.1554, Accuracy: 23.90%, LR: 0.00100, Val Loss: 128.2601, Val Accuracy: 23.14%\n",
      "Validating model on test data:\n",
      "Accuracy of the network on the test images: 23.75 %\n",
      "Per-class accuracy for model:\n",
      "Accuracy of apple : 51.00 %\n",
      "Accuracy of aquarium_fish : 26.00 %\n",
      "Accuracy of baby  : 17.00 %\n",
      "Accuracy of bear  : 9.00 %\n",
      "Accuracy of beaver : 9.00 %\n",
      "Accuracy of bed   : 23.00 %\n",
      "Accuracy of bee   : 15.00 %\n",
      "Accuracy of beetle : 19.00 %\n",
      "Accuracy of bicycle : 22.00 %\n",
      "Accuracy of bottle : 36.00 %\n",
      "Accuracy of bowl  : 6.00 %\n",
      "Accuracy of boy   : 6.00 %\n",
      "Accuracy of bridge : 14.00 %\n",
      "Accuracy of bus   : 21.00 %\n",
      "Accuracy of butterfly : 13.00 %\n",
      "Accuracy of camel : 12.00 %\n",
      "Accuracy of can   : 9.00 %\n",
      "Accuracy of castle : 47.00 %\n",
      "Accuracy of caterpillar : 23.00 %\n",
      "Accuracy of cattle : 21.00 %\n",
      "Accuracy of chair : 46.00 %\n",
      "Accuracy of chimpanzee : 37.00 %\n",
      "Accuracy of clock : 12.00 %\n",
      "Accuracy of cloud : 41.00 %\n",
      "Accuracy of cockroach : 39.00 %\n",
      "Accuracy of couch : 17.00 %\n",
      "Accuracy of crab  : 11.00 %\n",
      "Accuracy of crocodile : 7.00 %\n",
      "Accuracy of cup   : 32.00 %\n",
      "Accuracy of dinosaur : 17.00 %\n",
      "Accuracy of dolphin : 19.00 %\n",
      "Accuracy of elephant : 9.00 %\n",
      "Accuracy of flatfish : 16.00 %\n",
      "Accuracy of forest : 28.00 %\n",
      "Accuracy of fox   : 11.00 %\n",
      "Accuracy of girl  : 17.00 %\n",
      "Accuracy of hamster : 30.00 %\n",
      "Accuracy of house : 21.00 %\n",
      "Accuracy of kangaroo : 10.00 %\n",
      "Accuracy of keyboard : 20.00 %\n",
      "Accuracy of lamp  : 4.00 %\n",
      "Accuracy of lawn_mower : 38.00 %\n",
      "Accuracy of leopard : 21.00 %\n",
      "Accuracy of lion  : 32.00 %\n",
      "Accuracy of lizard : 8.00 %\n",
      "Accuracy of lobster : 3.00 %\n",
      "Accuracy of man   : 9.00 %\n",
      "Accuracy of maple_tree : 41.00 %\n",
      "Accuracy of motorcycle : 50.00 %\n",
      "Accuracy of mountain : 48.00 %\n",
      "Accuracy of mouse : 2.00 %\n",
      "Accuracy of mushroom : 19.00 %\n",
      "Accuracy of oak_tree : 45.00 %\n",
      "Accuracy of orange : 64.00 %\n",
      "Accuracy of orchid : 23.00 %\n",
      "Accuracy of otter : 0.00 %\n",
      "Accuracy of palm_tree : 54.00 %\n",
      "Accuracy of pear  : 20.00 %\n",
      "Accuracy of pickup_truck : 21.00 %\n",
      "Accuracy of pine_tree : 7.00 %\n",
      "Accuracy of plain : 63.00 %\n",
      "Accuracy of plate : 24.00 %\n",
      "Accuracy of poppy : 27.00 %\n",
      "Accuracy of porcupine : 24.00 %\n",
      "Accuracy of possum : 9.00 %\n",
      "Accuracy of rabbit : 8.00 %\n",
      "Accuracy of raccoon : 7.00 %\n",
      "Accuracy of ray   : 19.00 %\n",
      "Accuracy of road  : 58.00 %\n",
      "Accuracy of rocket : 29.00 %\n",
      "Accuracy of rose  : 37.00 %\n",
      "Accuracy of sea   : 42.00 %\n",
      "Accuracy of seal  : 6.00 %\n",
      "Accuracy of shark : 45.00 %\n",
      "Accuracy of shrew : 7.00 %\n",
      "Accuracy of skunk : 46.00 %\n",
      "Accuracy of skyscraper : 44.00 %\n",
      "Accuracy of snail : 6.00 %\n",
      "Accuracy of snake : 1.00 %\n",
      "Accuracy of spider : 12.00 %\n",
      "Accuracy of squirrel : 10.00 %\n",
      "Accuracy of streetcar : 14.00 %\n",
      "Accuracy of sunflower : 59.00 %\n",
      "Accuracy of sweet_pepper : 37.00 %\n",
      "Accuracy of table : 2.00 %\n",
      "Accuracy of tank  : 42.00 %\n",
      "Accuracy of telephone : 32.00 %\n",
      "Accuracy of television : 24.00 %\n",
      "Accuracy of tiger : 12.00 %\n",
      "Accuracy of tractor : 27.00 %\n",
      "Accuracy of train : 15.00 %\n",
      "Accuracy of trout : 40.00 %\n",
      "Accuracy of tulip : 24.00 %\n",
      "Accuracy of turtle : 7.00 %\n",
      "Accuracy of wardrobe : 60.00 %\n",
      "Accuracy of whale : 38.00 %\n",
      "Accuracy of willow_tree : 19.00 %\n",
      "Accuracy of wolf  : 23.00 %\n",
      "Accuracy of woman : 12.00 %\n",
      "Accuracy of worm  : 2.00 %\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 25\n",
    "learning_rate = 0.001\n",
    "weight_decay = 1e-4\n",
    "lr_factor = 0.29\n",
    "patience = 5\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "validation_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "conv_net = ConvNetWithBN(num_classes=100)\n",
    "conv_net.to(device)\n",
    "conv_net.device = device\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion = criterion.to(conv_net.device)\n",
    "\n",
    "optimizer_conv_net, scheduler = new_create_optimizer(conv_net, learning_rate=learning_rate, weight_decay=weight_decay, lr_factor=lr_factor, patience=patience)\n",
    "\n",
    "print(\"Training started...\")\n",
    "new_train(conv_net, train_loader, validation_loader, criterion, optimizer_conv_net, scheduler, epochs=epochs)\n",
    "\n",
    "print(\"Validating model on test data:\")\n",
    "accuracy = new_validate(conv_net, test_loader)\n",
    "\n",
    "print(\"Per-class accuracy for model:\")\n",
    "validate_per_class(conv_net, test_loader, classes)\n",
    "\n",
    "torch.save(conv_net.state_dict(), 'conv_net_with_bn.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create the new network models with extra layers and processes ###\n",
    "\n",
    "class TwoLayerNetImproved(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, hidden_size3, num_classes):\n",
    "        '''\n",
    "        Initializes the two-layer neural network model.\n",
    "\n",
    "        Args:\n",
    "            input_size (int): The size of the input features.\n",
    "            hidden_size (int): The size of the hidden layer.\n",
    "            num_classes (int): The number of classes in the dataset.\n",
    "        '''\n",
    "\n",
    "        super(TwoLayerNetImproved, self).__init__()\n",
    "\n",
    "        self.layer1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.layer2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.layer3 = nn.Linear(hidden_size2, hidden_size3)\n",
    "        self.layer4 = nn.Linear(hidden_size3, num_classes)\n",
    "\n",
    "        self.activation = nn.LeakyReLU(negative_slope=0.01)\n",
    "        self.dropout1 = nn.Dropout(p=0.2)\n",
    "        \n",
    "        self.batch_norm1 = nn.BatchNorm1d(hidden_size1)\n",
    "        self.batch_norm2 = nn.BatchNorm1d(hidden_size2)\n",
    "        self.batch_norm3 = nn.BatchNorm1d(hidden_size3)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        Defines the forward pass of the neural network.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): The input tensor.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The output tensor.\n",
    "        '''\n",
    "\n",
    "        a1 = self.activation(self.batch_norm1(self.layer1(self.flatten(x))))\n",
    "        a1 = self.dropout1(a1)\n",
    "        a2 = self.activation(self.batch_norm2(self.layer2(a1)))\n",
    "        a2 = self.dropout1(a2)\n",
    "        a3 = self.activation(self.batch_norm3(self.layer3(a2)))\n",
    "        a3 = self.dropout1(a3)\n",
    "        output = self.layer4(a3)\n",
    "        \n",
    "        return output\n",
    "\n",
    "\n",
    "class ConvNetImproved(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        '''\t\n",
    "        Initializes the convolutional neural network model.\n",
    "\n",
    "        Args:\n",
    "            None\n",
    "        '''\n",
    "\n",
    "        super(ConvNetImproved, self).__init__()\n",
    "\n",
    "        # based on the LeNet-5 architecture. \n",
    "        # Added 3 convolutional layers, batch normalization, skip connections, max pooling and dropout.\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding='same') # 32x32x3 --> 32x32x16\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding='same') # 32x32x16 --> 32x32x32\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding='same') # 32x32x32 --> 32x32x32\n",
    "        self.conv4 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding='same') # 16x16x32 --> 16x16x64\n",
    "        self.conv5 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding='same') # 16x16x64 --> 16x16x64\n",
    "\n",
    "        self.res_conv1 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=1, stride=1, padding='same')\n",
    "        self.res_conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=1, stride=1, padding='same')\n",
    "\n",
    "        self.activation = nn.LeakyReLU(negative_slope=0.01)\n",
    "        self.max_pooling = nn.MaxPool2d(kernel_size=2)\n",
    "        self.dropout1 = nn.Dropout(p=0.35)\n",
    "        self.dropout2 = nn.Dropout(p=0.2)\n",
    "        \n",
    "        self.batch_norm1 = nn.BatchNorm2d(16)\n",
    "        self.batch_norm2a = nn.BatchNorm2d(32)\n",
    "        self.batch_norm2b = nn.BatchNorm2d(32)\n",
    "        self.batch_norm3a = nn.BatchNorm2d(64)\n",
    "        self.batch_norm3b = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(in_features=4096, out_features=512)\n",
    "        self.fc2 = nn.Linear(in_features=512, out_features=128)\n",
    "        self.fc3 = nn.Linear(in_features=128, out_features=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        Defines the forward pass of the neural network.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): The input tensor.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The output tensor.\n",
    "        '''\n",
    "\n",
    "        x = self.activation(self.batch_norm1(self.conv1(x)))\n",
    "\n",
    "        sc_residual = self.res_conv1(x)\n",
    "\n",
    "        x = self.activation(self.batch_norm2a(self.conv2(x)))\n",
    "        x = self.batch_norm2b(self.conv3(x))\n",
    "        x = self.activation(x + sc_residual)\n",
    "        x = self.max_pooling(x) # 32x32x32 --> 16x16x32\n",
    "\n",
    "        sc_residual = self.res_conv2(x)\n",
    "\n",
    "        x = self.activation(self.batch_norm3a(self.conv4(x)))\n",
    "        x = self.batch_norm3b(self.conv5(x))\n",
    "        x = self.activation(x + sc_residual)\n",
    "        x = self.max_pooling(x) # 16x16x64 --> 8x8x64\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout1(self.activation(self.fc1(x)))\n",
    "        x = self.dropout2(self.activation(self.fc2(x)))\n",
    "        output = self.fc3(x)\n",
    "        \n",
    "        return output\n",
    "\n",
    "  \n",
    "def new_create_optimizer(model, learning_rate=0.001, weight_decay=1e-4, lr_factor=0.1, patience=5):\n",
    "    '''\n",
    "    Creates an optimizer for the model.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The neural network model.\n",
    "        learning_rate (float): The learning rate for the optimizer.\n",
    "\n",
    "    Returns:\n",
    "        torch.optim.AdamW: The optimizer for the model.\n",
    "    '''\n",
    "\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=lr_factor, patience=patience)\n",
    "    return optimizer, scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the performance of TwoLayerNet after hyperparameter tuning and compare it with the ConvNet model. Provide a detailed explanation of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started...\n",
      "Epoch [1/40], Loss: 3.9823, Accuracy: 8.91%, LR: 0.00100, Val Loss: 149.5686, Val Accuracy: 12.46%\n",
      "Epoch [2/40], Loss: 3.6752, Accuracy: 13.18%, LR: 0.00100, Val Loss: 141.8710, Val Accuracy: 16.00%\n",
      "Epoch [3/40], Loss: 3.5480, Accuracy: 15.69%, LR: 0.00100, Val Loss: 138.6878, Val Accuracy: 16.86%\n",
      "Epoch [4/40], Loss: 3.4696, Accuracy: 17.22%, LR: 0.00100, Val Loss: 135.8272, Val Accuracy: 19.26%\n",
      "Epoch [5/40], Loss: 3.3994, Accuracy: 18.29%, LR: 0.00100, Val Loss: 133.4152, Val Accuracy: 20.74%\n",
      "Epoch [6/40], Loss: 3.3478, Accuracy: 19.21%, LR: 0.00100, Val Loss: 131.6655, Val Accuracy: 20.54%\n",
      "Epoch [7/40], Loss: 3.3051, Accuracy: 19.82%, LR: 0.00100, Val Loss: 130.4103, Val Accuracy: 21.10%\n",
      "Epoch [8/40], Loss: 3.2664, Accuracy: 20.59%, LR: 0.00100, Val Loss: 128.8082, Val Accuracy: 22.54%\n",
      "Epoch [9/40], Loss: 3.2330, Accuracy: 21.28%, LR: 0.00100, Val Loss: 126.9367, Val Accuracy: 22.90%\n",
      "Epoch [10/40], Loss: 3.2029, Accuracy: 21.82%, LR: 0.00100, Val Loss: 125.8758, Val Accuracy: 24.02%\n",
      "Epoch [11/40], Loss: 3.1722, Accuracy: 22.16%, LR: 0.00100, Val Loss: 124.9363, Val Accuracy: 24.26%\n",
      "Epoch [12/40], Loss: 3.1503, Accuracy: 22.67%, LR: 0.00100, Val Loss: 124.6099, Val Accuracy: 24.68%\n",
      "Epoch [13/40], Loss: 3.1223, Accuracy: 23.31%, LR: 0.00100, Val Loss: 122.9850, Val Accuracy: 25.14%\n",
      "Epoch [14/40], Loss: 3.0912, Accuracy: 23.64%, LR: 0.00100, Val Loss: 122.0455, Val Accuracy: 25.86%\n",
      "Epoch [15/40], Loss: 3.0700, Accuracy: 24.32%, LR: 0.00100, Val Loss: 122.2986, Val Accuracy: 25.66%\n",
      "Epoch [16/40], Loss: 3.0508, Accuracy: 24.39%, LR: 0.00100, Val Loss: 120.9320, Val Accuracy: 26.72%\n",
      "Epoch [17/40], Loss: 3.0299, Accuracy: 24.90%, LR: 0.00100, Val Loss: 121.6113, Val Accuracy: 26.24%\n",
      "Epoch [18/40], Loss: 3.0062, Accuracy: 25.30%, LR: 0.00100, Val Loss: 120.2456, Val Accuracy: 27.06%\n",
      "Epoch [19/40], Loss: 2.9872, Accuracy: 25.94%, LR: 0.00100, Val Loss: 120.3310, Val Accuracy: 27.36%\n",
      "Epoch [20/40], Loss: 2.9730, Accuracy: 26.00%, LR: 0.00100, Val Loss: 119.3986, Val Accuracy: 26.56%\n",
      "Epoch [21/40], Loss: 2.9607, Accuracy: 26.40%, LR: 0.00100, Val Loss: 118.4879, Val Accuracy: 27.88%\n",
      "Epoch [22/40], Loss: 2.9373, Accuracy: 26.76%, LR: 0.00100, Val Loss: 118.1687, Val Accuracy: 28.62%\n",
      "Epoch [23/40], Loss: 2.9224, Accuracy: 27.06%, LR: 0.00100, Val Loss: 116.7837, Val Accuracy: 29.28%\n",
      "Epoch [24/40], Loss: 2.9074, Accuracy: 27.38%, LR: 0.00100, Val Loss: 117.9120, Val Accuracy: 28.06%\n",
      "Epoch [25/40], Loss: 2.8952, Accuracy: 27.36%, LR: 0.00100, Val Loss: 116.6936, Val Accuracy: 28.36%\n",
      "Epoch [26/40], Loss: 2.8766, Accuracy: 27.96%, LR: 0.00100, Val Loss: 116.0700, Val Accuracy: 28.94%\n",
      "Epoch [27/40], Loss: 2.8687, Accuracy: 28.08%, LR: 0.00100, Val Loss: 115.4482, Val Accuracy: 29.34%\n",
      "Epoch [28/40], Loss: 2.8482, Accuracy: 28.51%, LR: 0.00100, Val Loss: 115.8193, Val Accuracy: 29.34%\n",
      "Epoch [29/40], Loss: 2.8468, Accuracy: 28.26%, LR: 0.00100, Val Loss: 116.0032, Val Accuracy: 29.12%\n",
      "Epoch [30/40], Loss: 2.8367, Accuracy: 28.58%, LR: 0.00100, Val Loss: 114.5375, Val Accuracy: 30.06%\n",
      "Epoch [31/40], Loss: 2.8183, Accuracy: 28.87%, LR: 0.00100, Val Loss: 114.8416, Val Accuracy: 29.68%\n",
      "Epoch [32/40], Loss: 2.8051, Accuracy: 29.17%, LR: 0.00100, Val Loss: 115.4443, Val Accuracy: 29.32%\n",
      "Epoch [33/40], Loss: 2.7943, Accuracy: 29.30%, LR: 0.00100, Val Loss: 114.5919, Val Accuracy: 29.60%\n",
      "Epoch [34/40], Loss: 2.7777, Accuracy: 29.74%, LR: 0.00100, Val Loss: 114.1340, Val Accuracy: 30.38%\n",
      "Epoch [35/40], Loss: 2.7625, Accuracy: 30.01%, LR: 0.00100, Val Loss: 113.2399, Val Accuracy: 30.04%\n",
      "Epoch [36/40], Loss: 2.7533, Accuracy: 30.13%, LR: 0.00100, Val Loss: 113.0970, Val Accuracy: 30.46%\n",
      "Epoch [37/40], Loss: 2.7515, Accuracy: 29.82%, LR: 0.00100, Val Loss: 113.3365, Val Accuracy: 30.64%\n",
      "Epoch [38/40], Loss: 2.7393, Accuracy: 30.39%, LR: 0.00100, Val Loss: 113.1733, Val Accuracy: 29.60%\n",
      "Epoch [39/40], Loss: 2.7259, Accuracy: 30.61%, LR: 0.00100, Val Loss: 112.5207, Val Accuracy: 30.62%\n",
      "Epoch [40/40], Loss: 2.7159, Accuracy: 30.86%, LR: 0.00100, Val Loss: 113.1706, Val Accuracy: 29.76%\n",
      "Validating model on test data:\n",
      "Accuracy of the network on the test images: 30.57 %\n",
      "Per-class accuracy for model:\n",
      "Accuracy of apple : 68.00 %\n",
      "Accuracy of aquarium_fish : 51.00 %\n",
      "Accuracy of baby  : 21.00 %\n",
      "Accuracy of bear  : 13.00 %\n",
      "Accuracy of beaver : 10.00 %\n",
      "Accuracy of bed   : 31.00 %\n",
      "Accuracy of bee   : 36.00 %\n",
      "Accuracy of beetle : 33.00 %\n",
      "Accuracy of bicycle : 31.00 %\n",
      "Accuracy of bottle : 37.00 %\n",
      "Accuracy of bowl  : 14.00 %\n",
      "Accuracy of boy   : 13.00 %\n",
      "Accuracy of bridge : 27.00 %\n",
      "Accuracy of bus   : 24.00 %\n",
      "Accuracy of butterfly : 17.00 %\n",
      "Accuracy of camel : 21.00 %\n",
      "Accuracy of can   : 23.00 %\n",
      "Accuracy of castle : 54.00 %\n",
      "Accuracy of caterpillar : 37.00 %\n",
      "Accuracy of cattle : 22.00 %\n",
      "Accuracy of chair : 56.00 %\n",
      "Accuracy of chimpanzee : 51.00 %\n",
      "Accuracy of clock : 18.00 %\n",
      "Accuracy of cloud : 45.00 %\n",
      "Accuracy of cockroach : 58.00 %\n",
      "Accuracy of couch : 13.00 %\n",
      "Accuracy of crab  : 12.00 %\n",
      "Accuracy of crocodile : 27.00 %\n",
      "Accuracy of cup   : 43.00 %\n",
      "Accuracy of dinosaur : 24.00 %\n",
      "Accuracy of dolphin : 35.00 %\n",
      "Accuracy of elephant : 29.00 %\n",
      "Accuracy of flatfish : 23.00 %\n",
      "Accuracy of forest : 30.00 %\n",
      "Accuracy of fox   : 33.00 %\n",
      "Accuracy of girl  : 25.00 %\n",
      "Accuracy of hamster : 33.00 %\n",
      "Accuracy of house : 17.00 %\n",
      "Accuracy of kangaroo : 12.00 %\n",
      "Accuracy of keyboard : 27.00 %\n",
      "Accuracy of lamp  : 27.00 %\n",
      "Accuracy of lawn_mower : 48.00 %\n",
      "Accuracy of leopard : 24.00 %\n",
      "Accuracy of lion  : 31.00 %\n",
      "Accuracy of lizard : 20.00 %\n",
      "Accuracy of lobster : 11.00 %\n",
      "Accuracy of man   : 26.00 %\n",
      "Accuracy of maple_tree : 42.00 %\n",
      "Accuracy of motorcycle : 44.00 %\n",
      "Accuracy of mountain : 41.00 %\n",
      "Accuracy of mouse : 4.00 %\n",
      "Accuracy of mushroom : 20.00 %\n",
      "Accuracy of oak_tree : 80.00 %\n",
      "Accuracy of orange : 60.00 %\n",
      "Accuracy of orchid : 42.00 %\n",
      "Accuracy of otter : 0.00 %\n",
      "Accuracy of palm_tree : 37.00 %\n",
      "Accuracy of pear  : 26.00 %\n",
      "Accuracy of pickup_truck : 28.00 %\n",
      "Accuracy of pine_tree : 29.00 %\n",
      "Accuracy of plain : 76.00 %\n",
      "Accuracy of plate : 36.00 %\n",
      "Accuracy of poppy : 38.00 %\n",
      "Accuracy of porcupine : 23.00 %\n",
      "Accuracy of possum : 8.00 %\n",
      "Accuracy of rabbit : 12.00 %\n",
      "Accuracy of raccoon : 9.00 %\n",
      "Accuracy of ray   : 34.00 %\n",
      "Accuracy of road  : 76.00 %\n",
      "Accuracy of rocket : 41.00 %\n",
      "Accuracy of rose  : 42.00 %\n",
      "Accuracy of sea   : 64.00 %\n",
      "Accuracy of seal  : 9.00 %\n",
      "Accuracy of shark : 39.00 %\n",
      "Accuracy of shrew : 22.00 %\n",
      "Accuracy of skunk : 52.00 %\n",
      "Accuracy of skyscraper : 53.00 %\n",
      "Accuracy of snail : 11.00 %\n",
      "Accuracy of snake : 20.00 %\n",
      "Accuracy of spider : 18.00 %\n",
      "Accuracy of squirrel : 12.00 %\n",
      "Accuracy of streetcar : 24.00 %\n",
      "Accuracy of sunflower : 65.00 %\n",
      "Accuracy of sweet_pepper : 33.00 %\n",
      "Accuracy of table : 22.00 %\n",
      "Accuracy of tank  : 50.00 %\n",
      "Accuracy of telephone : 26.00 %\n",
      "Accuracy of television : 21.00 %\n",
      "Accuracy of tiger : 17.00 %\n",
      "Accuracy of tractor : 34.00 %\n",
      "Accuracy of train : 23.00 %\n",
      "Accuracy of trout : 48.00 %\n",
      "Accuracy of tulip : 10.00 %\n",
      "Accuracy of turtle : 19.00 %\n",
      "Accuracy of wardrobe : 64.00 %\n",
      "Accuracy of whale : 51.00 %\n",
      "Accuracy of willow_tree : 23.00 %\n",
      "Accuracy of wolf  : 43.00 %\n",
      "Accuracy of woman : 7.00 %\n",
      "Accuracy of worm  : 31.00 %\n"
     ]
    }
   ],
   "source": [
    "### Train both new models with similar hyperparameters from the ones found ###\n",
    "\n",
    "# model parameters\n",
    "hidden_size1 = 1536\n",
    "hidden_size2 = 768\n",
    "hidden_size3 = 256\n",
    "\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "weight_decay = 1e-5\n",
    "lr_factor = 0.3\n",
    "patience = 5\n",
    "epochs = 40\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "validation_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Create the model\n",
    "two_layer_net = TwoLayerNetImproved(32 * 32 * 3, hidden_size1, hidden_size2, hidden_size3, 100)\n",
    "two_layer_net.to(device)\n",
    "two_layer_net.device = device\n",
    "\n",
    "# create the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion = criterion.to(two_layer_net.device)\n",
    "\n",
    "# Optimizer for the model\n",
    "optimizer_two_layer_net, scheduler = new_create_optimizer(two_layer_net, learning_rate=learning_rate, weight_decay=weight_decay, lr_factor=lr_factor, patience=patience)\n",
    "\n",
    "print(\"Training started...\")\n",
    "new_train(two_layer_net, train_loader, validation_loader, criterion, optimizer_two_layer_net, scheduler, epochs=epochs)\n",
    "\n",
    "print(\"Validating model on test data:\")\n",
    "accuracy = new_validate(two_layer_net, test_loader)\n",
    "\n",
    "print(\"Per-class accuracy for model:\")\n",
    "validate_per_class(two_layer_net, test_loader, classes)\n",
    "\n",
    "torch.save(conv_net.state_dict(), 'two_layer_net_improved.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the performance of ConvNet after hyperparameter tuning and compare it with the TwoLayerNet model. Provide a detailed explanation of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started...\n",
      "Epoch [1/50], Loss: 4.1009, Accuracy: 6.69%, LR: 0.00100, Val Loss: 147.4826, Val Accuracy: 12.66%\n",
      "Epoch [2/50], Loss: 3.5520, Accuracy: 14.96%, LR: 0.00100, Val Loss: 131.4359, Val Accuracy: 19.84%\n",
      "Epoch [3/50], Loss: 3.2393, Accuracy: 20.41%, LR: 0.00100, Val Loss: 123.1178, Val Accuracy: 23.24%\n",
      "Epoch [4/50], Loss: 3.0185, Accuracy: 24.35%, LR: 0.00100, Val Loss: 112.3197, Val Accuracy: 29.10%\n",
      "Epoch [5/50], Loss: 2.8208, Accuracy: 28.36%, LR: 0.00100, Val Loss: 106.3123, Val Accuracy: 32.46%\n",
      "Epoch [6/50], Loss: 2.6601, Accuracy: 31.54%, LR: 0.00100, Val Loss: 99.1696, Val Accuracy: 36.32%\n",
      "Epoch [7/50], Loss: 2.5538, Accuracy: 33.58%, LR: 0.00100, Val Loss: 98.1831, Val Accuracy: 35.38%\n",
      "Epoch [8/50], Loss: 2.4568, Accuracy: 35.85%, LR: 0.00100, Val Loss: 93.9301, Val Accuracy: 38.22%\n",
      "Epoch [9/50], Loss: 2.3804, Accuracy: 37.27%, LR: 0.00100, Val Loss: 93.0865, Val Accuracy: 39.56%\n",
      "Epoch [10/50], Loss: 2.3139, Accuracy: 38.84%, LR: 0.00100, Val Loss: 89.7525, Val Accuracy: 40.36%\n",
      "Epoch [11/50], Loss: 2.2648, Accuracy: 39.80%, LR: 0.00100, Val Loss: 88.6776, Val Accuracy: 41.26%\n",
      "Epoch [12/50], Loss: 2.2124, Accuracy: 41.06%, LR: 0.00100, Val Loss: 87.2565, Val Accuracy: 41.88%\n",
      "Epoch [13/50], Loss: 2.1674, Accuracy: 42.19%, LR: 0.00100, Val Loss: 85.4072, Val Accuracy: 43.30%\n",
      "Epoch [14/50], Loss: 2.1243, Accuracy: 42.76%, LR: 0.00100, Val Loss: 85.6007, Val Accuracy: 43.78%\n",
      "Epoch [15/50], Loss: 2.0905, Accuracy: 43.54%, LR: 0.00100, Val Loss: 83.4236, Val Accuracy: 45.00%\n",
      "Epoch [16/50], Loss: 2.0493, Accuracy: 44.39%, LR: 0.00100, Val Loss: 82.5215, Val Accuracy: 45.44%\n",
      "Epoch [17/50], Loss: 2.0275, Accuracy: 45.31%, LR: 0.00100, Val Loss: 81.7006, Val Accuracy: 45.88%\n",
      "Epoch [18/50], Loss: 1.9981, Accuracy: 45.93%, LR: 0.00100, Val Loss: 81.1265, Val Accuracy: 46.20%\n",
      "Epoch [19/50], Loss: 1.9746, Accuracy: 46.32%, LR: 0.00100, Val Loss: 80.1401, Val Accuracy: 45.90%\n",
      "Epoch [20/50], Loss: 1.9566, Accuracy: 46.63%, LR: 0.00100, Val Loss: 80.3196, Val Accuracy: 47.46%\n",
      "Epoch [21/50], Loss: 1.9345, Accuracy: 47.07%, LR: 0.00100, Val Loss: 79.1235, Val Accuracy: 47.22%\n",
      "Epoch [22/50], Loss: 1.9039, Accuracy: 47.73%, LR: 0.00100, Val Loss: 77.8699, Val Accuracy: 47.78%\n",
      "Epoch [23/50], Loss: 1.8795, Accuracy: 48.22%, LR: 0.00100, Val Loss: 76.5164, Val Accuracy: 48.94%\n",
      "Epoch [24/50], Loss: 1.8671, Accuracy: 48.77%, LR: 0.00100, Val Loss: 78.0098, Val Accuracy: 47.48%\n",
      "Epoch [25/50], Loss: 1.8560, Accuracy: 48.82%, LR: 0.00100, Val Loss: 77.7999, Val Accuracy: 48.80%\n",
      "Epoch [26/50], Loss: 1.8380, Accuracy: 49.40%, LR: 0.00100, Val Loss: 75.5392, Val Accuracy: 48.56%\n",
      "Epoch [27/50], Loss: 1.8247, Accuracy: 49.73%, LR: 0.00100, Val Loss: 75.1381, Val Accuracy: 48.94%\n",
      "Epoch [28/50], Loss: 1.7978, Accuracy: 50.08%, LR: 0.00100, Val Loss: 76.5541, Val Accuracy: 49.38%\n",
      "Epoch [29/50], Loss: 1.8011, Accuracy: 50.51%, LR: 0.00100, Val Loss: 75.0309, Val Accuracy: 50.28%\n",
      "Epoch [30/50], Loss: 1.7799, Accuracy: 50.59%, LR: 0.00100, Val Loss: 75.1282, Val Accuracy: 50.54%\n",
      "Epoch [31/50], Loss: 1.7514, Accuracy: 51.50%, LR: 0.00100, Val Loss: 74.7953, Val Accuracy: 50.62%\n",
      "Epoch [32/50], Loss: 1.7436, Accuracy: 51.42%, LR: 0.00100, Val Loss: 75.5470, Val Accuracy: 49.48%\n",
      "Epoch [33/50], Loss: 1.7420, Accuracy: 51.69%, LR: 0.00100, Val Loss: 75.6212, Val Accuracy: 50.36%\n",
      "Epoch [34/50], Loss: 1.7382, Accuracy: 51.60%, LR: 0.00100, Val Loss: 74.9826, Val Accuracy: 50.02%\n",
      "Epoch [35/50], Loss: 1.7151, Accuracy: 52.13%, LR: 0.00100, Val Loss: 74.4355, Val Accuracy: 49.98%\n",
      "Epoch [36/50], Loss: 1.7006, Accuracy: 52.66%, LR: 0.00100, Val Loss: 73.9598, Val Accuracy: 51.20%\n",
      "Epoch [37/50], Loss: 1.6933, Accuracy: 52.54%, LR: 0.00100, Val Loss: 73.4523, Val Accuracy: 51.98%\n",
      "Epoch [38/50], Loss: 1.6903, Accuracy: 52.96%, LR: 0.00100, Val Loss: 73.3244, Val Accuracy: 51.18%\n",
      "Epoch [39/50], Loss: 1.6775, Accuracy: 53.09%, LR: 0.00100, Val Loss: 72.6848, Val Accuracy: 51.10%\n",
      "Epoch [40/50], Loss: 1.6624, Accuracy: 53.40%, LR: 0.00100, Val Loss: 72.8135, Val Accuracy: 51.26%\n",
      "Epoch [41/50], Loss: 1.6564, Accuracy: 53.36%, LR: 0.00100, Val Loss: 74.1254, Val Accuracy: 51.50%\n",
      "Epoch [42/50], Loss: 1.6514, Accuracy: 53.80%, LR: 0.00100, Val Loss: 73.9314, Val Accuracy: 52.22%\n",
      "Epoch [43/50], Loss: 1.6286, Accuracy: 54.14%, LR: 0.00100, Val Loss: 71.9000, Val Accuracy: 52.52%\n",
      "Epoch [44/50], Loss: 1.6225, Accuracy: 54.48%, LR: 0.00100, Val Loss: 72.5739, Val Accuracy: 52.54%\n",
      "Epoch [45/50], Loss: 1.6267, Accuracy: 54.56%, LR: 0.00100, Val Loss: 72.4235, Val Accuracy: 52.48%\n",
      "Epoch [46/50], Loss: 1.6192, Accuracy: 54.52%, LR: 0.00100, Val Loss: 72.0958, Val Accuracy: 52.22%\n",
      "Epoch [47/50], Loss: 1.6003, Accuracy: 54.59%, LR: 0.00100, Val Loss: 72.8036, Val Accuracy: 51.58%\n",
      "Epoch [48/50], Loss: 1.5992, Accuracy: 55.17%, LR: 0.00100, Val Loss: 72.1335, Val Accuracy: 51.90%\n",
      "Epoch [49/50], Loss: 1.5999, Accuracy: 55.29%, LR: 0.00100, Val Loss: 71.1377, Val Accuracy: 52.26%\n",
      "Epoch [50/50], Loss: 1.5819, Accuracy: 55.32%, LR: 0.00100, Val Loss: 71.6577, Val Accuracy: 52.64%\n",
      "Validating model on test data:\n",
      "Accuracy of the network on the test images: 52.91 %\n",
      "Per-class accuracy for model:\n",
      "Accuracy of apple : 81.00 %\n",
      "Accuracy of aquarium_fish : 65.00 %\n",
      "Accuracy of baby  : 44.00 %\n",
      "Accuracy of bear  : 33.00 %\n",
      "Accuracy of beaver : 39.00 %\n",
      "Accuracy of bed   : 52.00 %\n",
      "Accuracy of bee   : 68.00 %\n",
      "Accuracy of beetle : 42.00 %\n",
      "Accuracy of bicycle : 66.00 %\n",
      "Accuracy of bottle : 66.00 %\n",
      "Accuracy of bowl  : 36.00 %\n",
      "Accuracy of boy   : 20.00 %\n",
      "Accuracy of bridge : 55.00 %\n",
      "Accuracy of bus   : 44.00 %\n",
      "Accuracy of butterfly : 50.00 %\n",
      "Accuracy of camel : 37.00 %\n",
      "Accuracy of can   : 50.00 %\n",
      "Accuracy of castle : 80.00 %\n",
      "Accuracy of caterpillar : 44.00 %\n",
      "Accuracy of cattle : 48.00 %\n",
      "Accuracy of chair : 74.00 %\n",
      "Accuracy of chimpanzee : 74.00 %\n",
      "Accuracy of clock : 47.00 %\n",
      "Accuracy of cloud : 58.00 %\n",
      "Accuracy of cockroach : 70.00 %\n",
      "Accuracy of couch : 31.00 %\n",
      "Accuracy of crab  : 42.00 %\n",
      "Accuracy of crocodile : 47.00 %\n",
      "Accuracy of cup   : 73.00 %\n",
      "Accuracy of dinosaur : 38.00 %\n",
      "Accuracy of dolphin : 46.00 %\n",
      "Accuracy of elephant : 45.00 %\n",
      "Accuracy of flatfish : 43.00 %\n",
      "Accuracy of forest : 53.00 %\n",
      "Accuracy of fox   : 50.00 %\n",
      "Accuracy of girl  : 40.00 %\n",
      "Accuracy of hamster : 55.00 %\n",
      "Accuracy of house : 55.00 %\n",
      "Accuracy of kangaroo : 36.00 %\n",
      "Accuracy of keyboard : 65.00 %\n",
      "Accuracy of lamp  : 42.00 %\n",
      "Accuracy of lawn_mower : 69.00 %\n",
      "Accuracy of leopard : 53.00 %\n",
      "Accuracy of lion  : 65.00 %\n",
      "Accuracy of lizard : 25.00 %\n",
      "Accuracy of lobster : 34.00 %\n",
      "Accuracy of man   : 31.00 %\n",
      "Accuracy of maple_tree : 54.00 %\n",
      "Accuracy of motorcycle : 87.00 %\n",
      "Accuracy of mountain : 73.00 %\n",
      "Accuracy of mouse : 26.00 %\n",
      "Accuracy of mushroom : 47.00 %\n",
      "Accuracy of oak_tree : 55.00 %\n",
      "Accuracy of orange : 88.00 %\n",
      "Accuracy of orchid : 64.00 %\n",
      "Accuracy of otter : 7.00 %\n",
      "Accuracy of palm_tree : 74.00 %\n",
      "Accuracy of pear  : 61.00 %\n",
      "Accuracy of pickup_truck : 63.00 %\n",
      "Accuracy of pine_tree : 40.00 %\n",
      "Accuracy of plain : 87.00 %\n",
      "Accuracy of plate : 64.00 %\n",
      "Accuracy of poppy : 60.00 %\n",
      "Accuracy of porcupine : 54.00 %\n",
      "Accuracy of possum : 26.00 %\n",
      "Accuracy of rabbit : 26.00 %\n",
      "Accuracy of raccoon : 51.00 %\n",
      "Accuracy of ray   : 41.00 %\n",
      "Accuracy of road  : 79.00 %\n",
      "Accuracy of rocket : 70.00 %\n",
      "Accuracy of rose  : 60.00 %\n",
      "Accuracy of sea   : 74.00 %\n",
      "Accuracy of seal  : 23.00 %\n",
      "Accuracy of shark : 46.00 %\n",
      "Accuracy of shrew : 31.00 %\n",
      "Accuracy of skunk : 70.00 %\n",
      "Accuracy of skyscraper : 81.00 %\n",
      "Accuracy of snail : 43.00 %\n",
      "Accuracy of snake : 35.00 %\n",
      "Accuracy of spider : 50.00 %\n",
      "Accuracy of squirrel : 27.00 %\n",
      "Accuracy of streetcar : 47.00 %\n",
      "Accuracy of sunflower : 84.00 %\n",
      "Accuracy of sweet_pepper : 32.00 %\n",
      "Accuracy of table : 45.00 %\n",
      "Accuracy of tank  : 53.00 %\n",
      "Accuracy of telephone : 61.00 %\n",
      "Accuracy of television : 67.00 %\n",
      "Accuracy of tiger : 78.00 %\n",
      "Accuracy of tractor : 62.00 %\n",
      "Accuracy of train : 51.00 %\n",
      "Accuracy of trout : 64.00 %\n",
      "Accuracy of tulip : 52.00 %\n",
      "Accuracy of turtle : 24.00 %\n",
      "Accuracy of wardrobe : 85.00 %\n",
      "Accuracy of whale : 57.00 %\n",
      "Accuracy of willow_tree : 50.00 %\n",
      "Accuracy of wolf  : 64.00 %\n",
      "Accuracy of woman : 17.00 %\n",
      "Accuracy of worm  : 54.00 %\n"
     ]
    }
   ],
   "source": [
    "# model parameters\n",
    "batch_size = 128\n",
    "learning_rate = 0.001\n",
    "weight_decay = 1e-4\n",
    "lr_factor = 0.29\n",
    "patience = 5\n",
    "epochs = 50\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "validation_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Create the model\n",
    "conv_net = ConvNetImproved(100)\n",
    "conv_net.to(device)\n",
    "conv_net.device = device\n",
    "\n",
    "# create the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion = criterion.to(conv_net.device)\n",
    "\n",
    "# Optimizer for the model\n",
    "optimizer_conv_net, scheduler = new_create_optimizer(conv_net, learning_rate=learning_rate, weight_decay=weight_decay, lr_factor=lr_factor, patience=patience)\n",
    "\n",
    "print(\"Training started...\")\n",
    "new_train(conv_net, train_loader, validation_loader, criterion, optimizer_conv_net, scheduler, epochs=epochs)\n",
    "print(\"Validating model on test data:\")\n",
    "accuracy = new_validate(conv_net, test_loader)\n",
    "\n",
    "print(\"Per-class accuracy for model:\")\n",
    "validate_per_class(conv_net, test_loader, classes)\n",
    "\n",
    "torch.save(conv_net.state_dict(), 'conv_net_improved.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section-8\"></a>\n",
    "### **Section 8: Visualizing the STL-10 Dataset and Preparing the Data Loader (3 points)**\n",
    "\n",
    "In this section, you will work with a subset of the [STL-10](https://cs.stanford.edu/~acoates/stl10/) dataset, containing higher resolution images and different object classes than CIFAR-100. Before fine-tuning your ConvNet on this dataset, first complete the `visualise_stl10` function to display sample images from the following 5 classes:\n",
    "\n",
    "1. **Bird**\n",
    "2. **Deer**\n",
    "3. **Dog**\n",
    "4. **Horse**\n",
    "5. **Monkey**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise_stl10(class_mapping):\n",
    "    '''\n",
    "    Visualizes 5 images from each specified class in the STL-10 dataset.\n",
    "\n",
    "    Args:\n",
    "        class_mapping (dict): A dictionary mapping class indices to class names.\n",
    "    '''\n",
    "\n",
    "    # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the class mapping for bird, deer, dog, horse, and monkey\n",
    "class_mapping = {1: 'bird', 4: 'deer', 5: 'dog', 6: 'horse', 7: 'monkey'}\n",
    "\n",
    "# Visualize STL-10 classes\n",
    "visualise_stl10(class_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After visualizing the data, implement the `STL10_loader` class to create a custom data loader that initializes the dataset, extracts the target classes, and applies the necessary image transformations. Once these tasks are completed, you will move on to fine-tuning the ConvNet on this dataset in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class STL10_loader(Dataset):\n",
    "    def __init__(self, root, train=True, transform=None):\n",
    "        '''\n",
    "        Initializes the STL10 dataset.\n",
    "\n",
    "        Args:\n",
    "            root (str): Root directory of the dataset.\n",
    "            train (bool): If True, use the training set, otherwise use the test set.\n",
    "            transform (callable, optional): A function/transform to apply to the images.\n",
    "        '''\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "    def __len__(self):\n",
    "        '''\n",
    "        Returns the number of samples in the dataset.\n",
    "        '''\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "        Retrieves a sample from the dataset at the specified index.\n",
    "\n",
    "        Args:\n",
    "            idx (int): The index of the sample to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            tuple: A tuple containing the transformed image and its target label.\n",
    "        '''\n",
    "\n",
    "        # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section-9\"></a>\n",
    "### **Section 9: Fine-tuning ConvNet on STL-10 (14 points)**\n",
    "\n",
    "In this section, you will load the pre-trained parameters of the ConvNet (trained on CIFAR-100) and modify the output layer to adapt it to the new dataset containing 5 classes. You can either first load the pre-trained parameters and then modify the output layer, or change the output layer before loading the matched pre-trained parameters. Once modified, you will train the model and document the settings of hyperparameters, accuracy, and learning curve. Additionally, visualize both the training loss and accuracy to assess the learning process. To gain a deeper understanding of the feature learning process, consider using techniques like [**t-sne**](https://lvdmaaten.github.io/tsne/) for feature space visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section-10\"></a>\n",
    "### **Section 10: Bonus Challenge (optional)**\n",
    "\n",
    "Try to achieve the highest possible accuracy on the test dataset (5 classes from STL-10) by adjusting hyperparameters, modifying architectures, or applying techniques like data augmentation. The top-performing teams will earn bonus points that can significantly boost their final lab grade, even allowing it to exceed 10 (up to 11):\n",
    "\n",
    "- **1st place:** +1.0 to the final grade of the final lab\n",
    "- **2nd place:** +0.8 to the final grade of the final lab\n",
    "- **3rd place:** +0.6 to the final grade of the final lab\n",
    "- **4th place:** +0.4 to the final grade of the final lab\n",
    "- **5th place:** +0.2 to the final grade of the final lab\n",
    "\n",
    "**Hint:** You may use techniques like data augmentation, freezing early layers, modifying architecture, or optimizing hyperparameters. Only data from CIFAR-100 and STL-10 can be used, and you cannot add more than 3 additional convolutional layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section-x\"></a>\n",
    "### **Section X: Individual Contribution Report *(Mandatory)***\n",
    "\n",
    "Because we want each student to contribute fairly to the submitted work, we ask you to fill out the textcells below. Write down your contribution to each of the assignment components in percentages. Naturally, percentages for one particular component should add up to 100% (e.g. 30% - 30% - 40%). No further explanation has to be given."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Name | Contribution on Research | Contribution on Programming | Contribution on Writing |\n",
    "| -------- | ------- | ------- | ------- |\n",
    "| Jose | 33 % | 33 % | 33 % |\n",
    "| Lisanne | 33 % | 33 % | 33 % |\n",
    "| Julio | 33 % | 33 % | 33 % |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - End of Notebook -"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv1_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
